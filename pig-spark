#!/bin/bash

# Getting started
#
# Compile spark with hadoop 2.2.0 -SPARK_HADOOP_VERSION=2.2.0 SPARK_YARN=true ./sbt/sbt clean assembly to generate spark.jar

# Compile pig with -Dhadoopversion=23 flag

# Configure following environment variables to run it on YARN cluster


# Follow this guide for for enabling running spork: 
##	http://docs.sigmoidanalytics.com/index.php/Setting_up_spork_with_spark_0.8.1

export HADOOP_CONF_DIR=/home/akhld/mobi/localcluster/hadoop/conf
export HADOOP_HOME=/home/akhld/mobi/localcluster/hadoop/

# Not necessary after SPARK-1053
#export SPARK_YARN_APP_JAR=build/pig-withouthadoop.jar 

# To debug OOMs
#export SPARK_JAVA_OPTS=" -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heap.dump"
#export SPARK_JAVA_OPTS+=" -Xdebug -Xrunjdwp:transport=dt_socket,address=12345,server=y,suspend=y"
# Settings to work with YARN, spark jar compiled with hadoop 2
export SPARK_MASTER=spark://127.0.0.1:7077

#if want to run on spark master
#export SPARK_MASTER=spark://-------:7077
#export MESOS_NATIVE_LIBRARY= <libmesos.so>
####


# jars to ship, pig-withouthadoop.jar to workaround Classloader issue

# Pig settings
export PIG_CLASSPATH=/home/akhld/mobi/localcluster/codes/pig/build/ivy/lib/Pig/netty-3.6.6.Final.jar:/home/akhld/mobi/localcluster/codes/pig/pig-withouthadoop.jar:/home/akhld/mobi/localcluster/codes/pig/lib/spark/mesos-0.9.0.jar:/home/akhld/mobi/localcluster/codes/pig/build/ivy/lib/Pig/*:$HADOOP_CONF_DIR:/home/akhld/mobi/localcluster/codes/pig/conf
#export PIG_CLASSPATH=/home/akhld/mobi/localcluster/codes/pig/pig-withouthadoop.jar:/home/akhld/mobi/localcluster/hadoop/:/home/akhld/mobi/localcluster/codes/pig/conf

export SPARK_JARS="/home/akhld/mobi/localcluster/codes/pig/build/pig-0.12.0-SNAPSHOT-withdependencies.jar,/home/akhld/mobi/localcluster/codes/pig/build/ivy/lib/Pig/twitter4j-core-3.0.3.jar,/home/akhld/mobi/localcluster/codes/pig/build/ivy/lib/Pig/twitter4j-stream-3.0.3.jar"

export SPARK_PIG_JAR=/home/akhld/mobi/localcluster/codes/pig/pig.jar

#export HADOOP_COMMON_HOME=/home/akhld/mobi/localcluster/hadoop
#export HADOOP_INSTALL=/home/akhld/mobi/localcluster/hadoop
#export PIG_CLASSPATH=/home/akhld/mobi/localcluster/hadoop/:/home/akhld/mobi/localcluster/codes/pig/conf
export PIG_HOME=/home/akhld/mobi/localcluster/codes/pig
export SPARK_HOME=/home/akhld/mobi/localcluster/spark
#export SPARK_JAR=/home/akhld/mobi/localcluster/codes/pig/build/ivy/lib/Pig/spark-core_2.9.3-0.8.1-incubating.jar
#export SPARK_MASTER=spark://akhldz:7077

# Cluster settings
export SPARK_WORKER_CORES=1
export SPARK_WORKER_MEMORY=512m
export SPARK_MEM=512m
export SPARK_WORKER_INSTANCES=1

bin/pig -x spark "$@"
